{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4123e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f115530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-15 22:05:26--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘./paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "./paul_graham/paul_ 100%[===================>]  73.28K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2025-04-15 22:05:26 (4.72 MB/s) - ‘./paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p './paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O './paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdb628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader('./paul_graham/').load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac7f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Initialize the sentence splitter with desired parameters\n",
    "node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
    "\n",
    "# Assuming 'documents' is a list of Document objects\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6417af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes[0].text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b968a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "\n",
    "my_activeloop_id = \"charanvardhan\"\n",
    "my_activeloop_dataset = \"LlamaIndex_paulgraham_essay\"\n",
    "dataset_path = f\"hub://{my_activeloop_id}/{my_activeloop_dataset}\"\n",
    "\n",
    "# Create a DeepLake vector storepip install deeplake[enterprise]\n",
    "vector_store = DeepLakeVectorStore(\n",
    "    dataset_path=dataset_path,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b70db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c26cd522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 42\n",
      "First 5 node IDs: ['ce233fec-43f7-4485-a6c2-11c4ebb3711b', '73dbc5e2-1125-4abc-bcb6-156b2eadef87', '273cc0b9-bc0c-4faf-9da6-939b79ca0cac', 'b1e4ada7-9b66-47f0-a531-679d34f6a674', '5fa72a97-3b4d-4730-95d8-b6b8721d3170']\n"
     ]
    }
   ],
   "source": [
    "all_node_ids = list(storage_context.docstore.docs.keys())\n",
    "print(f\"Total nodes: {len(all_node_ids)}\")\n",
    "print(\"First 5 node IDs:\", all_node_ids[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "992ccc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes = [storage_context.docstore.get_node(node_id) for node_id in all_node_ids]\n",
    "all_nodes[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae553cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497b3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(streaming=True, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b47b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is involved in funding startups through a program called the Summer Founders Program, where he invests in and supports young entrepreneurs. He also organizes talks with experts on startups, provides funding to selected groups of founders, and offers guidance and resources to help them succeed. Additionally, he is involved in creating a community of startup founders through his program, which fosters collaboration and support among the participants."
     ]
    }
   ],
   "source": [
    "streaming_response = query_engine.query(\n",
    "    \"What does Paul Graham do?\",\n",
    ")\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccd32c",
   "metadata": {},
   "source": [
    "## SubQuestion Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6911be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f70d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "query_engine_tools = [QueryEngineTool\n",
    "                     (\n",
    "                        query_engine=query_engine,\n",
    "                        metadata=ToolMetadata(\n",
    "                            name=\"pg_essay\",\n",
    "                            description=\"Paul Graaham essay on what i worked on\"\n",
    "                        ),\n",
    "                     ),]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07a936e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.sub_question_query_engine.SubQuestionQueryEngine at 0x11b1d9c90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed2265ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e12afc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What did Paul Graham work on before Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: What did Paul Graham work on during Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: What did Paul Graham work on after Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: Before Y Combinator, Paul Graham worked on a new version of Arc with Robert in the summer of 2006. They created a faster version of Arc by compiling it into Scheme. As a test for this new Arc, Paul Graham wrote Hacker News, originally intended as a news aggregator for startup founders but later changed to cater to future startup founders and cover topics that engaged intellectual curiosity.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] A: During Y Combinator, Paul Graham worked on various projects such as organizing a Summer Founders Program, investing in startups, and creating a news aggregator called Hacker News.\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] A: After Y Combinator, Paul Graham worked on a new version of Arc with Robert in the summer of 2006. He compiled it into Scheme and used it to create Hacker News, originally intended as a news aggregator for startup founders but later changed to cater to future startup founders and topics of intellectual curiosity.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How was Paul Grahams life different before, during, and after YC?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f976bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final response :\n",
      " Paul Graham's life involved working on a new version of Arc with Robert before Y Combinator, during which they created a faster version of Arc by compiling it into Scheme and developed Hacker News. During Y Combinator, he focused on organizing a Summer Founders Program, investing in startups, and creating Hacker News. After Y Combinator, he continued working on a new version of Arc with Robert, compiling it into Scheme, and using it to create Hacker News, which evolved to cater to future startup founders and topics of intellectual curiosity.\n"
     ]
    }
   ],
   "source": [
    "print( \"The final response :\\n\", response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135060ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaIndex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
