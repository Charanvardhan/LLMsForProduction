{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91808fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e698c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb01fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI \n",
    "language models: PaLM. The search giant is launching an API for PaLM alongside\n",
    "a number of AI enterprise tools it says will help businesses “generate text, \n",
    "mages, code, videos, audio, and more from simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by \n",
    "OpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April\n",
    "2022. Like other LLMs, PaLM is a flexible system that can potentially carry \n",
    "out all sorts of text generation and editing tasks. You could train PaLM to \n",
    "be a conversational chatbot like ChatGPT, for example, or you could use it \n",
    "for tasks like summarizing text or even writing code. (It’s similar to features \n",
    "Google also announced today for its Workspace apps like Google Docs and Gmail.)\"\"\"\n",
    "\n",
    "with open(\"my.txt\",\"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bc151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"my.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0cc470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 374, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\\nGoogle is offering developers access to one of its most advanced AI \\nlanguage models: PaLM. The search giant is launching an API for PaLM alongside\\na number of AI enterprise tools it says will help businesses “generate text, \\nmages, code, videos, audio, and more from simple natural language prompts.”', metadata={'source': 'my.txt'}), Document(page_content='PaLM is a large language model, or LLM, similar to the GPT series created by \\nOpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April\\n2022. Like other LLMs, PaLM is a flexible system that can potentially carry \\nout all sorts of text generation and editing tasks. You could train PaLM to \\nbe a conversational chatbot like ChatGPT, for example, or you could use it \\nfor tasks like summarizing text or even writing code. (It’s similar to features \\nGoogle also announced today for its Workspace apps like Google Docs and Gmail.)', metadata={'source': 'my.txt'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print((docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ce82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector embedding of each chunk\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86cf5c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://charanvardhan/indexesAndRetreivers already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:06<00:00,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://charanvardhan/indexesAndRetreivers', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      "   text       text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1395a684-13fe-11f0-a8e7-0e8d4396c6f5',\n",
       " '1395a742-13fe-11f0-a8e7-0e8d4396c6f5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to store this in vector data stores.\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "my_activeloop_ord_id = \"charanvardhan\"\n",
    "my_activeloop_dataset_name = \"indexesAndRetreivers\"\n",
    "dataset_path = f\"hub://{my_activeloop_ord_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f214a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a88e76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charanmannuru/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain/llms/openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/charanmannuru/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain/llms/openai.py:753: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "#create a retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(model_name='gpt-3.5-turbo'),\n",
    "    chain_type='stuff',\n",
    "    retriever= retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ceda137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google plans to challenge OpenAI by offering developers access to its advanced AI language model PaLM, launching an API for PaLM, and providing AI enterprise tools for businesses to generate text, images, code, videos, audio, and more from natural language prompts.\n"
     ]
    }
   ],
   "source": [
    "query = \"How Google plans to challenge OpenAI?\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c78ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d58d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
